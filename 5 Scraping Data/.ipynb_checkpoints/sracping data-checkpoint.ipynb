{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b2743e-3b6b-48b1-86dd-6ac9e3c691f1",
   "metadata": {},
   "source": [
    "# โปรแกรมดึงข้อมูลจาก Github\n",
    "\n",
    "### ลักษณะของโปรแกรม\n",
    "- ทำการดึงข้อมูลจากแต่ละหมวด(Topic) ในเว็บไซต์ Github 30 หมวดแรก\n",
    "- ทำการดึงข้อมูลจากแต่ละ Repository ของหมวดนั้นอีกที 30 Reopository โดยเรียงจากดาวมากที่สุดขึ้นก่อน\n",
    "- บันทึกข้อมูลลงในไฟล์ csv \n",
    "\n",
    "### Framework ที่ใช้\n",
    "- pandas\n",
    "- requests\n",
    "- beaurifulsoup4\n",
    "\n",
    "### อ้างอิง Tutorial\n",
    "- ปรับแต่งฟังก์ชันมาจากแหล่งการสอนเว็บไซต์นี้ : https://www.youtube.com/watch?v=RKsLLG-bzEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e631f0ee-5943-46d7-a1e3-326b50516107",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet\n",
    "!pip install pandas --upgrade --quiet\n",
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bfd502d-0399-4250-a0a4-2bf124491b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb2c74-a07c-48b9-99ae-bf0d3bec06c3",
   "metadata": {},
   "source": [
    "## กำหนดตัวแปรต่างๆ ที่สำคัญได้แก่\n",
    "- set_header กำหนดค่าให้ server ได้ทราบว่าของมูลของ client เป็นอย่างไร สามารถป้อนกันระบบอาจเข้าใจว่าเราคือ bot ได้นิดนึง\n",
    "- github_url กำหนดเป็นปลายทางที่ต้องการดึงข้อมูล\n",
    "- doc เก็บข้อมูล html ที่ดึงมาด้วย bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a39ad3d-2fd3-4f73-93d4-0c376ea48e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_header = {'User-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36'}\n",
    "github_url = \"https://github.com/topics\" \n",
    "\n",
    "response = requests.get(github_url, headers = set_header)\n",
    "page_content = response.text\n",
    "response.status_code\n",
    "\n",
    "doc = BeautifulSoup(page_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e14ee0-bcab-4b84-9e48-18d6acb286a0",
   "metadata": {},
   "source": [
    "## ฟังก์ชันสำหรับการทำงานกับหมวดใน Github\n",
    "- get_topic_title นำเอกสารที่ผ่านการแปลงจาก bs4 เป็นอาร์กิวเมนต์ ผลลัพธ์ที่ได้เป็นชื่อหมวดหมู่ ใน Github\n",
    "- get_topic_desc นำเอกสารที่ผ่านการแปลงจาก bs4 เป็นอาร์กิวเมนต์ ผลลัพธ์ที่ได้เป็นคำอธิบายของหมวดหมู่ใน Github\n",
    "- get_topic_url นำเอกสารที่ผ่านการแปลงจาก bs4 เป็นอาร์กิวเมนต์ ผลลัพธ์ที่ได้เป็น url ปลายทางของหมวดหมู่ สามารถคลิกเพื่อข้อไปที่หมวดหมู่นั้นได้เลย\n",
    "- scrape_topics ไปต้องนำอาร์กิวเมนต์เข้าไปประมวลผล ผลลัพธ์ที่ได้เป็นข้อมูล Dataframe ของหมวดหมู่ทั้งหมด\n",
    "- list_all_topics ทำการบันทึกข้อมูลหัวข้อ 30 หมวดแรก เป็นไฟล์ csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f76feb-659d-45bc-bd7f-766a1d908c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_title(doc):\n",
    "    selection_class = \"f3 lh-condensed mb-0 mt-1 Link--primary\"\n",
    "    topic_title_tag = doc.find_all('p', {\"class\" : selection_class})\n",
    "    topic_title = []\n",
    "    for tag in topic_title_tag:\n",
    "        topic_title.append(tag.text)\n",
    "    return topic_title\n",
    "\n",
    "def get_topic_desc(doc):\n",
    "    desc_class = \"f5 color-text-secondary mb-0 mt-1\"\n",
    "    topic_desc_tag = doc.find_all('p', {\"class\" : desc_class})\n",
    "    topic_desc = []\n",
    "    for tag in topic_desc_tag:\n",
    "        topic_desc.append(tag.text.strip())\n",
    "    return topic_desc\n",
    "\n",
    "def get_topic_url(doc):\n",
    "    base_url = \"https://github.com\"\n",
    "    url_class = \"d-flex no-underline\"\n",
    "    topic_utl_tag = doc.find_all('a', {\"class\" : url_class})\n",
    "    topic_url = []\n",
    "    for tag in topic_utl_tag:\n",
    "        topic_url.append(base_url + tag[\"href\"])\n",
    "    return topic_url\n",
    "\n",
    "def scrape_topics():\n",
    "    topics_url = \"https://github.com/topics\"\n",
    "    response = requests.get(topics_url, headers = set_header)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception('failed to loadpage'.format( topics_url))\n",
    "    topic_dict = {\n",
    "        'title': get_topic_title(doc),\n",
    "        'description' : get_topic_desc(doc),\n",
    "        \"Link\" : get_topic_url(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topic_dict)\n",
    "\n",
    "def list_all_topics():\n",
    "    scrape_topics().to_csv('All Top Topic.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e561696-8a0d-449f-b54a-7b29ee7108f4",
   "metadata": {},
   "source": [
    "## ฟังชั่นสำหรับการแปลงตัวเลข\n",
    "ทำการแปลงตัวเลขที่ลงท้ายด้วย k ด้วยการคูณ 1,000 เข้าไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0201bfa7-d7eb-4851-bb5f-3024d77710c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_count_star(stars_str):\n",
    "    stars_str = stars_str.strip()\n",
    "    if stars_str[-1] == 'k':\n",
    "        return int(float(stars_str[:-1]) * 1000) \n",
    "    return int(stars_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e8ff6-ee5a-47c6-b53e-9cfd1f8dbf18",
   "metadata": {},
   "source": [
    "## ฟังก์ชันสำหรับการเข้าถึงเอกสาร Repository\n",
    "เมื่อเรียกใช้จะได้เอกสารที่ผ่านการแปลงจาก bs4\n",
    "พารามิเตอร์เป็นตัวเลขของหมวดที่เราต้องการเข้าถึง \n",
    "- ดูตัวเลขได้จากลำดับในฟังก์ชัน get_topic_url หรือ หมวดหมู่ที่ได้จากการดึงข้อมูลครั้งก่อน\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130144f5-4c3c-460a-9c2c-e944a709710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    topic = get_topic_url(doc)[topic_url]\n",
    "    response = requests.get(topic, headers = set_header)\n",
    "    \n",
    "#     check status\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('failed to loadpage '.format(topic))\n",
    "    \n",
    "#     parsing\n",
    "    topic_page_doc = BeautifulSoup( response.text, 'html.parser')\n",
    "\n",
    "    return topic_page_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d17c96-667d-4f2d-baae-b628b044764a",
   "metadata": {},
   "source": [
    "## ฟังก์ชันสำหรับ Repository\n",
    "- get_repo_info รวบรวมข้อมูลของ Repository ได้แก่ ชื่อผู้ใช้, ชื่อ repo, ดาวที่ได้รับ, การเข้าถึง url\n",
    "- get_topic_repos ข้อมูล Dataframe ของ repository พารามิเตอร์เป็นตัวเลขของหมวดที่เราต้องการเข้าถึง \n",
    "- srape_repo_topic ทำการบันทึกข้อมูล Dataframe เป็นไฟล์ csv แล้วเก็บไว้ในไฟล์ folder ชื่อ file_scraping\n",
    "- ถ้าหากว่าข้อมูลที่บันทึกตรงกับชื่อไฟล์ที่กำลังจะบันทึกใหม่ ระบบจะไม่บันทึกให้ต้องทำการลบออกก่อน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6da90fe-eb99-4ae2-872b-475ca8eed4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(repo_tags, star_tags):\n",
    "    \n",
    "    base_repo_url = 'https://github.com'\n",
    "    \n",
    "    username = repo_tags.find_all('a')[0].text.strip()\n",
    "    repo_name = repo_tags.find_all('a')[1].text.strip()\n",
    "    repo_url = base_repo_url + repo_tags.find_all('a')[1]['href']\n",
    "    stars = parse_count_star(star_tags.text.strip())\n",
    "    \n",
    "    return username, repo_name, stars, repo_url\n",
    "\n",
    "def get_topic_repos(topic_url):\n",
    "    topic_repo_doc = get_topic_page(topic_url)\n",
    "    \n",
    "    h1_selection_class = 'f3 color-text-secondary text-normal lh-condensed'\n",
    "    star_selection_class = 'social-count float-none'\n",
    "    \n",
    "    repo_tags = topic_repo_doc.find_all('h1', {'class': h1_selection_class})\n",
    "    star_tags = topic_repo_doc.find_all('a', {'class' : star_selection_class })\n",
    "    \n",
    "    \n",
    "    topic_dicts = {\n",
    "        'username' : [],\n",
    "        'repo_names' : [],\n",
    "        'star' : [],\n",
    "        'repo_url': []\n",
    "    }\n",
    "\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        \n",
    "        topic_dicts['username'].append(repo_info[0])\n",
    "        topic_dicts['repo_names'].append(repo_info[1])\n",
    "        topic_dicts['star'].append(repo_info[2])\n",
    "        topic_dicts['repo_url'].append(repo_info[3])\n",
    "\n",
    "    topic_repo_df = pd.DataFrame(topic_dicts, index=None)\n",
    "    \n",
    "    return topic_repo_df\n",
    "\n",
    "def srape_repo_topic(topic_url):\n",
    "    os.makedirs('file_scraping', exist_ok=True)\n",
    "    fname = 'file_scraping/'+ get_topic_title(doc)[topic_url] + ' Topic.csv'\n",
    "    \n",
    "    if os.path.exists(fname):\n",
    "        print('file alredy exists skiping...{}'.format(fname))\n",
    "        return \n",
    "    print('scraping top repository in {}'.format(fname))\n",
    "    topic_df = get_topic_repos(topic_url)\n",
    "    topic_df.to_csv(fname, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74c4a4-b7e6-497a-aa57-cd0c3e55dd1d",
   "metadata": {},
   "source": [
    "## ฟังก์ชันสำหรับการบันทึกไฟล์เป็น csv \n",
    "- ข้อมูลที่ได้จากไฟล์เป็นข้อมูลของหมวดหมู่นั้น\n",
    "- พารามิเตอร์ใส่เป็นตัวเลข \n",
    "- ระบบจะทำการบันทึกไล่จากหมวดแรกไปถึงหมวดที่ระบุไว้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5835c4b-3c87-4eca-be89-46dc66500d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_repo_each_topic(list_number):\n",
    "    for i in range(list_number + 1):\n",
    "        srape_repo_topic(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68acf51-e7c7-4a35-9bba-2542b13ced53",
   "metadata": {},
   "source": [
    "### ทำการเรียกใช้ฟังก์ชัน list_all_topics และ scrape_all_repo_each_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "250cd3d2-68b4-46af-84e5-206e6f6b011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7fbd444-104c-47ba-8252-f35980f28b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file alredy exists skiping...file_scraping/3D Topic.csv\n",
      "file alredy exists skiping...file_scraping/Ajax Topic.csv\n",
      "file alredy exists skiping...file_scraping/Algorithm Topic.csv\n",
      "file alredy exists skiping...file_scraping/Amp Topic.csv\n",
      "file alredy exists skiping...file_scraping/Android Topic.csv\n",
      "file alredy exists skiping...file_scraping/Angular Topic.csv\n",
      "file alredy exists skiping...file_scraping/Ansible Topic.csv\n",
      "file alredy exists skiping...file_scraping/API Topic.csv\n"
     ]
    }
   ],
   "source": [
    "scrape_all_repo_each_topic(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad26e0b-5c45-41dc-81c4-0b6f7a5edcf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
